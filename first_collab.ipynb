{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_collab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q7PyeRFmiHe",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation with LSTM Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00EoEDm3TpT6",
        "colab_type": "text"
      },
      "source": [
        "#### First things first\n",
        "\n",
        "To prepare the notebook, google drive must be mounted and the directory with the relevant files (weights, modules, data etc) must be navigated to. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOTh2wN3JehQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0908db28-c0f4-4511-b751-768728b13256"
      },
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMfKMZ_XKiZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4000c990-7206-40c0-8e6e-e0562e21f54c"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\"\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " custom-weights-01-1.2951.hdf5\t second_collab.ipynb\n",
            " first_collab.ipynb\t\t starting-weight.hdf5\n",
            " get_docx_text.py\t\t'Summarizing word docs.py'\n",
            "'Processing word docs.py'\t'Tutorial Document Summary.py'\n",
            " __pycache__\t\t\t'Tutorial Summary Generation.py'\n",
            " README.md\t\t\t wonderland.txt\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9FPKr53S_rt",
        "colab_type": "text"
      },
      "source": [
        "## The Project Aims\n",
        "\n",
        "\n",
        "*   To create a contextual summary of a given document automatically\n",
        "*   To compare abilities of deep learning on control and real world data\n",
        "*   Understand deep learning's abilities and limitations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDjdnc9VVVcg",
        "colab_type": "text"
      },
      "source": [
        "#### The Project Ingredients\n",
        "\n",
        "\n",
        "*   A set of control data (the well known and used nltk corpus for Alice in Wonderland was chosen)\n",
        "\n",
        "*   A set of 'real world' data (some essays on a given topic were used for this experiment)\n",
        "*   The Spyder IDE, numpy, system modules (later transferred to Google Collab)\n",
        "*   Keras and related modules\n",
        "* A decent laptop (16GB RAM, RYZEN 7 CPU, RADEON VEGA GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meJdiTlYlnan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "063de5a9-70b7-4fd2-a524-863c96b84296"
      },
      "source": [
        "%%time\n",
        "#data manipulation\n",
        "import numpy\n",
        "import sys\n",
        "\n",
        "#keras modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.44 s, sys: 150 ms, total: 1.59 s\n",
            "Wall time: 1.67 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWeHb1aqmFCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def txtfile2txt(textfile):\n",
        "    \n",
        "    raw_text = open(textfile, 'r', encoding = 'utf-8')\n",
        "    raw_text = raw_text.read()\n",
        "    raw_text = raw_text.lower()\n",
        "    \n",
        "    return raw_text\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haYN9chbnAbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_file = \"wonderland.txt\"\n",
        "raw_text = txtfile2txt(text_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ8kpAWvnDj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhJes6gxnevN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b1be1b3b-b314-4c79-f6e5-886972128db6"
      },
      "source": [
        "%%time\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.57 s, sys: 73.9 ms, total: 1.64 s\n",
            "Wall time: 1.65 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbB5_GRAngiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5poKLGwinjre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.load_weights('starting-weight.hdf5')\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP-cZuTzoA_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define checkpoint\n",
        "#filepath=\"tutorial-weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "#callbacks_list = [checkpoint]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhR1GTGUqd2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f2ae0535-04c5-46d5-d5d4-88fc37b4e414"
      },
      "source": [
        "%%time\n",
        "#fit model\n",
        "#model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "model.fit(X, y, epochs=4, batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            " 86784/163681 [==============>...............] - ETA: 8:23 - loss: 1.8058"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jzqNzmxqgPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umn9XiiqtY_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2ZHDjygtteX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}